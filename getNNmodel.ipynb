{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###############头文件###########################\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from scipy import misc\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########神经网络搭建层############################\n",
    "def HappyModel(input_shape): \n",
    "\n",
    "    X_input = Input(shape=input_shape)\n",
    "    #X = ZeroPadding2D(padding=(1, 1))(X_input)\n",
    "    X = Convolution2D(8, kernel_size=(3,3), strides=(1,1))(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n",
    "    \n",
    "    #X = ZeroPadding2D(padding=(1, 1))(X)\n",
    "    X = Convolution2D(16, kernel_size=(3,3), strides=(1,1))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n",
    "    \n",
    "    #X = ZeroPadding2D(padding=(1, 1))(X)\n",
    "    X = Convolution2D(32, kernel_size=(3,3), strides=(1,1))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n",
    "    \n",
    "    # FC\n",
    "    X = Flatten()(X)\n",
    "    X =Dense(1, name='last')(X)\n",
    "    Y = Activation('sigmoid',name='y')(X) \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = Y, name='HappyModel')\n",
    "    \n",
    "    return model\n",
    "#######得阈值###############\n",
    "def getThreshold(mat,thre_proportion=0.1):\n",
    "    iter_rows = mat.shape[0];\n",
    "    iter_cols = mat.shape[1];\n",
    "    sum_pixel = iter_rows * iter_cols;\n",
    "    \n",
    "    histogram = np.zeros(256)\n",
    "    \n",
    "    for i in range(iter_rows):\n",
    "        for j in range(iter_cols):\n",
    "            #print(iter_rows,iter_cols)\n",
    "            histogram[mat[i,j]]+=1;\n",
    "    \n",
    "\n",
    "    left = thre_proportion * sum_pixel;\n",
    "    i = 255;\n",
    "    while(1):\n",
    "        left=left-histogram[i]\n",
    "        i-=1\n",
    "        if left < 0:\n",
    "            break\n",
    "    if i>0:\n",
    "        return i\n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "\n",
    "    \n",
    "#载入图片和预处理  参数分别为：图片地址，最终结果，临时测试变量\n",
    "def loadAndPre(address):\n",
    "    #预处理\n",
    "    img =cv2.imread(address,cv2.IMREAD_GRAYSCALE);\n",
    "    try:\n",
    "        img.shape \n",
    "    except:\n",
    "        return False,img;\n",
    "    else:\n",
    "        #调整大小 同比缩放至64*64以内\n",
    "        rows=img.shape[0]\n",
    "        cols=img.shape[1]\n",
    "        #print(img.shape)\n",
    "        if cols<rows :\n",
    "            img=cv2.resize(img,(int(cols*1.0/rows*fixedSize),fixedSize));\n",
    "        else:\n",
    "            img=cv2.resize(img,(fixedSize,int(rows*1.0/cols*fixedSize)));\n",
    "        rows=img.shape[0]\n",
    "        cols=img.shape[1]\n",
    "        #print(cols,rows,fixedSize)\n",
    "        #剪去边上多余部分\n",
    "        cutRatio1=int(0.15*cols);\n",
    "        cutRatio2=int(0.05*rows);\n",
    "        #blank=cv2.Mat((), img.type(), cv::Scalar(0));#新建空白\n",
    "        blank = np.zeros((fixedSize,fixedSize),dtype=np.uint8)  \n",
    "        mask=img[cutRatio2:rows-cutRatio2,cutRatio1:cols-cutRatio1]\n",
    "        blank[cutRatio2:rows-cutRatio2,cutRatio1:cols-cutRatio1]=mask\n",
    "        thre=getThreshold(blank);#//mean(forThres)[0];//均值获取阈值\n",
    "        \n",
    "        result=blank;\n",
    "        for i in range(result.shape[0]):\n",
    "            for j in range(result.shape[1]):\n",
    "                if(result[i, j]>thre):\n",
    "                    result[i, j]=200\n",
    "        #imshow(result)\n",
    "        #//cv::waitKey();\n",
    "        return True,result;\n",
    "\n",
    "################################\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/training/0\n",
      "./data/training/1\n",
      "./data/training/5\n",
      "./data/training/6\n",
      "./data/training/3\n",
      "./data/training/2\n",
      "./data/training/4\n",
      "./data/training/7\n",
      "count: 3901\n",
      "right:  2406\n",
      "bad:  1495\n",
      "no_good:  598\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "img_dir = './data/training/'  # 自己单独建的训练文件夹\n",
    "\n",
    "X_ori=[]\n",
    "Y_ori=[]\n",
    "fixedSize=32\n",
    "count = 0\n",
    "no_good=0\n",
    "right=0\n",
    "bad=0\n",
    "for guy in os.listdir(img_dir):  \n",
    "    person_dir = pjoin(img_dir, guy)  # 子文件夹的路径\n",
    "    print(person_dir)\n",
    "    for i in os.listdir(person_dir):# 子文件夹中的图片遍历\n",
    "        image_dir = pjoin(person_dir, i)  #每个文件夹中图片的路径\n",
    "        #是否能打开图片\n",
    "        #img = cv2.imread(image_dir)\n",
    "        flag,img=loadAndPre(image_dir)\n",
    "        if flag==False:\n",
    "            no_good+=1\n",
    "            continue\n",
    "        else:\n",
    "            x = img#image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=2)\n",
    "            #x = preprocess_input(x)\n",
    "            X_ori.append(x)\n",
    "            if guy==\"0\":#负样本文件夹\n",
    "                Y_ori.append(0)\n",
    "                bad+=1\n",
    "            else:\n",
    "                Y_ori.append(1)\n",
    "                right+=1\n",
    "            count = count+1\n",
    "    \n",
    "print(\"count:\",count)\n",
    "print(\"right: \",right)\n",
    "print(\"bad: \",bad)\n",
    "print(\"no_good: \",no_good)\n",
    "X_ori=np.array(X_ori)\n",
    "Y_ori=np.array(Y_ori)\n",
    "\n",
    "#print(X_ori.shape)\n",
    "#print(Y_ori.shape)\n",
    "\n",
    "X_ori = X_ori  # 标准化。z-score规范化。特征值减去均值，除以标准差。\n",
    "# 采用交叉验证，验证集占训练集10%/随机划分\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_ori, Y_ori, test_size=.1)  \n",
    "#print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/truth/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/truth/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/truth/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "3510/3510 [==============================] - 1s 427us/step - loss: 0.4042 - accuracy: 0.8541\n",
      "Epoch 2/20\n",
      "3510/3510 [==============================] - 1s 344us/step - loss: 0.1609 - accuracy: 0.9407\n",
      "Epoch 3/20\n",
      "3510/3510 [==============================] - 1s 342us/step - loss: 0.1261 - accuracy: 0.9598\n",
      "Epoch 4/20\n",
      "3510/3510 [==============================] - 1s 344us/step - loss: 0.1132 - accuracy: 0.9678\n",
      "Epoch 5/20\n",
      "3510/3510 [==============================] - 1s 345us/step - loss: 0.1036 - accuracy: 0.9658\n",
      "Epoch 6/20\n",
      "3510/3510 [==============================] - 1s 344us/step - loss: 0.0951 - accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "3510/3510 [==============================] - 1s 342us/step - loss: 0.0909 - accuracy: 0.9724\n",
      "Epoch 8/20\n",
      "3510/3510 [==============================] - 1s 342us/step - loss: 0.0826 - accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "3510/3510 [==============================] - 1s 343us/step - loss: 0.0759 - accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "3510/3510 [==============================] - 1s 343us/step - loss: 0.0739 - accuracy: 0.9752\n",
      "Epoch 11/20\n",
      "3510/3510 [==============================] - 1s 351us/step - loss: 0.0678 - accuracy: 0.9783\n",
      "Epoch 12/20\n",
      "3510/3510 [==============================] - 1s 343us/step - loss: 0.0621 - accuracy: 0.9803\n",
      "Epoch 13/20\n",
      "3510/3510 [==============================] - 1s 341us/step - loss: 0.0596 - accuracy: 0.9809\n",
      "Epoch 14/20\n",
      "3510/3510 [==============================] - 1s 341us/step - loss: 0.0555 - accuracy: 0.9838\n",
      "Epoch 15/20\n",
      "3510/3510 [==============================] - 1s 340us/step - loss: 0.0525 - accuracy: 0.9846\n",
      "Epoch 16/20\n",
      "3510/3510 [==============================] - 1s 343us/step - loss: 0.0496 - accuracy: 0.9843\n",
      "Epoch 17/20\n",
      "3510/3510 [==============================] - 1s 345us/step - loss: 0.0459 - accuracy: 0.9823\n",
      "Epoch 18/20\n",
      "3510/3510 [==============================] - 1s 344us/step - loss: 0.0437 - accuracy: 0.9852\n",
      "Epoch 19/20\n",
      "3510/3510 [==============================] - 1s 341us/step - loss: 0.0422 - accuracy: 0.9866\n",
      "Epoch 20/20\n",
      "3510/3510 [==============================] - 1s 340us/step - loss: 0.0375 - accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "#建立\n",
    "happyModel = HappyModel((fixedSize, fixedSize, 1))\n",
    "\n",
    "import keras\n",
    "happyModel.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#训练\n",
    "happyModel.fit(x=X_train, y=Y_train, batch_size=16, epochs=20)\n",
    "\n",
    "#保存相应文件\n",
    "with open('./info/arch2.json', 'w') as fout:\n",
    "    fout.write(happyModel.to_json())\n",
    "happyModel.save_weights('./info/weights2.h5', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存\n",
      "Model: \"HappyModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "last (Dense)                 (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "y (Activation)               (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 6,241\n",
      "Trainable params: 6,129\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 保存模型结构和参数到文件\n",
    "tf.keras.models.save_model(happyModel,\"myModel2.pb\") # 默认生成 .pb 格式模型，也可以通过save_format 设置 .h5 格式\n",
    "print('模型已保存')\n",
    "\n",
    "happyModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is : input_1:0\n",
      "output is: y/Sigmoid:0\n",
      "INFO:tensorflow:Froze 20 variables.\n",
      "INFO:tensorflow:Converted 20 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model/happyModel.pb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将keras写为pb\n",
    "\n",
    "#明确输入输出的名字\n",
    "print('input is :', happyModel.input.name)\n",
    "print ('output is:', happyModel.output.name)\n",
    "\n",
    "\n",
    "#Problem : Cannot find the variable that is input to the ReadVariableOp\n",
    "#Solution : K.set_learning_phase(0)\n",
    "\n",
    "#待操作的临时变量sess\n",
    "sess = K.get_session()\n",
    "#\n",
    "frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess,\n",
    "    sess.graph_def,\n",
    "    output_node_names=[\"y/Sigmoid\"])\n",
    " \n",
    "# 保存图为pb文件\n",
    "# with open('model.pb', 'wb') as f:\n",
    "#     f.write(frozen_graph_def.SerializeToString())\n",
    " \n",
    "tf.train.write_graph(frozen_graph_def, 'Model', 'happyModel.pb', as_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00032107]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Graph().as_default():\n",
    "    output_graph_def = tf.GraphDef()\n",
    " \n",
    "    with open('./Model/happyModel.pb', \"rb\") as f:\n",
    "        output_graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "        #初始化\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        #明确输入输出\n",
    "        input_x = sess.graph.get_tensor_by_name(\"input_1:0\")\n",
    "        output = sess.graph.get_tensor_by_name(\"y/Sigmoid:0\")\n",
    " \n",
    "        print(sess.run(output, feed_dict={input_x: X_ori[3].reshape(1, 32, 32, 1)}))\n",
    "        print(Y_ori[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#检验正确率\\nimg_dir=\"/home/truth/ClionProjects/RM/sp自瞄/attacktest/data/raw/\"\\ntotal=0\\ngood=0\\nbad=0;\\nfor guy in os.listdir(img_dir):  \\n    person_dir = pjoin(img_dir, guy)  # 子文件夹的路径\\n\\n    flag,img=loadAndPre(person_dir)\\n    if flag==False:\\n        no_good+=1\\n        continue\\n    else:\\n        x = img#image.img_to_array(img)\\n        x = np.expand_dims(x, axis=2)\\n\\n        x=x[None,:]\\n\\n        predict = happyModel.predict(x)\\n        if(predict>0.5):\\n            re=\"right\"\\n            good+=1\\n        else:\\n            \\n            bad+=1\\n\\n        total = total+1\\nprint(good/total)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#检验正确率\n",
    "img_dir=\"/home/truth/ClionProjects/RM/sp自瞄/attacktest/data/raw/\"\n",
    "total=0\n",
    "good=0\n",
    "bad=0;\n",
    "for guy in os.listdir(img_dir):  \n",
    "    person_dir = pjoin(img_dir, guy)  # 子文件夹的路径\n",
    "\n",
    "    flag,img=loadAndPre(person_dir)\n",
    "    if flag==False:\n",
    "        no_good+=1\n",
    "        continue\n",
    "    else:\n",
    "        x = img#image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=2)\n",
    "\n",
    "        x=x[None,:]\n",
    "\n",
    "        predict = happyModel.predict(x)\n",
    "        if(predict>0.5):\n",
    "            re=\"right\"\n",
    "            good+=1\n",
    "        else:\n",
    "            \n",
    "            bad+=1\n",
    "\n",
    "        total = total+1\n",
    "print(good/total)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
